{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-DUOtBCQmWK"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reading the dataset\n",
        "df = pd.read_csv('diabetes.csv')\n"
      ],
      "metadata": {
        "id": "NJerlbXHRAk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "U-J2rV7rRCPN",
        "outputId": "bb2bdad6-3c0b-40a0-8823-4091781804cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0              6      148             72             35        0  33.6   \n",
              "1              1       85             66             29        0  26.6   \n",
              "2              8      183             64              0        0  23.3   \n",
              "3              1       89             66             23       94  28.1   \n",
              "4              0      137             40             35      168  43.1   \n",
              "..           ...      ...            ...            ...      ...   ...   \n",
              "763           10      101             76             48      180  32.9   \n",
              "764            2      122             70             27        0  36.8   \n",
              "765            5      121             72             23      112  26.2   \n",
              "766            1      126             60              0        0  30.1   \n",
              "767            1       93             70             31        0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                       0.627   50        1  \n",
              "1                       0.351   31        0  \n",
              "2                       0.672   32        1  \n",
              "3                       0.167   21        0  \n",
              "4                       2.288   33        1  \n",
              "..                        ...  ...      ...  \n",
              "763                     0.171   63        0  \n",
              "764                     0.340   27        0  \n",
              "765                     0.245   30        0  \n",
              "766                     0.349   47        1  \n",
              "767                     0.315   23        0  \n",
              "\n",
              "[768 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-479b3114-de86-43c5-8518-7183a244d48c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-479b3114-de86-43c5-8518-7183a244d48c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-479b3114-de86-43c5-8518-7183a244d48c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-479b3114-de86-43c5-8518-7183a244d48c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UMTXB1SrRET4",
        "outputId": "b6241cc5-4526-4268-9eb5-865b2d689aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ee7bdd1-06e1-4266-bceb-6f54b2e58176\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ee7bdd1-06e1-4266-bceb-6f54b2e58176')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ee7bdd1-06e1-4266-bceb-6f54b2e58176 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ee7bdd1-06e1-4266-bceb-6f54b2e58176');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into input and target variables\n",
        "X = df.drop(['Outcome'], axis=1).values  # values takes only numerical values of the dataframe\n",
        "y = df['Outcome'].values"
      ],
      "metadata": {
        "id": "zgKDcO9aRH04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXqyZt1AROSW",
        "outputId": "310b5e44-442a-4e29-cc3c-68d331571407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "630GKMmNRSYE",
        "outputId": "fefbfd61-e1f3-4f1f-95bb-25255dcf98fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "hoviHs8DRVyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential() is a function that initializes a sequential model. A sequential model is a linear stack of layers, where you can add one layer at a time using the add() method.\n",
        "\n",
        "Dense() is a layer type that is used for a fully connected layer in the neural network. It means that every neuron in the previous layer is connected to every neuron in the current layer.\n",
        "\n",
        "Neural networks are composed of interconnected layers of artificial neurons, and each neuron has a certain number of units.\n",
        "\n",
        "Each unit in a neural network layer represents a node or a neuron. The number of units in a layer determines the dimensionality or size of that layer. The units in the input layer correspond to the number of features or inputs in your data. For example, if you have an input layer with 10 units, it means you have 10 features or variables.\n",
        "\n",
        "In subsequent layers, the number of units determines the number of artificial neurons in that layer. The units in these layers capture and learn various patterns, features, or representations from the input data. The higher the number of units, the more complex patterns the layer can learn.\n",
        "\n",
        "By adjusting the number of units in different layers, you can control the capacity and complexity of the neural network. It's important to strike a balance between having enough units to capture important features without overfitting the model to the training data.\n",
        "\n",
        "\n",
        "The first Dense() layer has 12 units and expects an input of shape (8,) because of input_dim=8. The activation function used in this layer is Rectified Linear Unit (ReLU), which is a popular activation function that introduces non-linearity to the neural network.\n",
        "\n",
        "The second Dense() layer has 8 units and also uses ReLU as the activation function.\n",
        "\n",
        "The final Dense() layer has 1 unit and uses sigmoid as the activation function. Sigmoid function returns a value between 0 and 1, which is suitable for binary classification problems where we want to predict the probability of an input belonging to a certain class.\n",
        "\n",
        "So, in summary, this is a simple neural network model with 2 hidden layers having 12 and 8 neurons respectively, and an output layer with 1 neuron for binary classification. The model uses ReLU as the activation function for the hidden layers and sigmoid as the activation function for the output layer.\n",
        "\n"
      ],
      "metadata": {
        "id": "rKVGxB4JG1LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "QIiBFnrTRmbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After building the neural network architecture, the next step is to compile the model. The compile() method configures the model for training by specifying the loss function, optimizer, and evaluation metrics.\n",
        "\n",
        "loss='binary_crossentropy' specifies the loss function to use during training. Binary cross-entropy is a commonly used loss function for binary classification problems, where we want to minimize the difference between the predicted probabilities and the true labels.\n",
        "\n",
        "optimizer='adam' specifies the optimization algorithm to use during training. Adam is a popular optimization algorithm that uses adaptive learning rates and momentum to converge faster and more reliably.\n",
        "\n",
        "metrics=['accuracy'] specifies the evaluation metric to use during training and testing. Accuracy is a metric that measures the fraction of correctly classified samples. It is a commonly used metric for classification problems.\n",
        "\n",
        "So, in summary, this code compiles the neural network model with binary cross-entropy as the loss function, Adam as the optimization algorithm, and accuracy as the evaluation metric.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EKfaFbkeHvQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "83d0Ym_mHzu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model# Keep increasing the Epoch and batch size till loss and accuracy remain at stagnant levels\n",
        "model.fit(X, y, epochs=150, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG3jpSz5SkUg",
        "outputId": "7b4d7dc0-913c-4069-d7ff-29948dad7eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 1s 2ms/step - loss: 2.3693 - accuracy: 0.4583\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.9832 - accuracy: 0.4440\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7527 - accuracy: 0.6107\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.6484\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6667\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6414 - accuracy: 0.6745\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6706\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6732\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.6836\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.6628\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.6732\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.6784\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.6745\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.6875\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.6667\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.6797\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.6862\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.6966\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.6992\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6901\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6836\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.6810\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7135\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.6927\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7201\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7135\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7018\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7188\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7109\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7096\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7161\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7201\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7083\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7422\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7266\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7253\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7214\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7253\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7292\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7370\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7161\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7214\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7357\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7461\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7331\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7383\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7370\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7266\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7318\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7409\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7383\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7487\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7422\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7370\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7240\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7305\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7396\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7500\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7396\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7474\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7435\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7526\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7461\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7435\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7474\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7409\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7461\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7461\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7513\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7409\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7422\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7565\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7552\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7539\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7500\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7513\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7539\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7383\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7526\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7500\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7357\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7526\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7552\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7383\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7552\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7448\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7526\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7526\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7539\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7539\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7591\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7526\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7513\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7643\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7734\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7487\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7591\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7474\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7656\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7461\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7552\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7539\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7539\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7669\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7526\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7617\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7552\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7539\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7539\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7617\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7591\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7617\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7539\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7578\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7617\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7487\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7734\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7669\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7695\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7656\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7786\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7747\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7643\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7682\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7708\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7669\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7565\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7617\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7721\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7682\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7682\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7552\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7552\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7617\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7734\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7656\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7669\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7630\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7786\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7747\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7708\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7656\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7552\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7682\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7617\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7630\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7721\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7656\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7760\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7734\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6e8c2b3fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "X represents the input data to the model, and y represents the corresponding target labels for the input data.\n",
        "\n",
        "epochs=150 specifies the number of times the model will iterate over the entire training dataset during training. One epoch means that the model has gone through the entire training dataset once.\n",
        "\n",
        "batch_size=10 specifies the number of samples that will be propagated through the network at once. The weights of the network will be updated based on the gradients calculated on these samples. This is known as stochastic gradient descent.\n",
        "\n",
        "During training, the model will forward propagate the input data through the network, compute the loss using the specified loss function, and then backpropagate the error to update the weights of the network using the specified optimizer. This process continues for the specified number of epochs or until the model reaches convergence.\n",
        "\n",
        "So, in summary, this code trains the compiled neural network model with the given input data X and target labels y for 150 epochs, with each epoch training the model on batches of 10 samples at a time.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wG3SDJrvI1Qy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "_, accuracy = model.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pj9H5vkTSlb",
        "outputId": "72e90cce-5cec-4e1d-9a10-bb4c4043ddd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7695\n",
            "Accuracy: 76.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.evaluate(X, y) is a method that evaluates the trained model on the given test data and returns the loss value and evaluation metric value(s) specified during model compilation.\n",
        "\n",
        "X represents the input data to the model, and y represents the corresponding target labels for the input data. The first output of the method (loss function) is ignored by assigning it to the dummy variable _, and the second output (accuracy)is assigned to the variable accuracy.\n",
        "\n",
        "So, in summary, this code evaluates the trained neural network model on the given test data X and target labels y and returns the calculated loss value, which is ignored, and the accuracy metric value, which is stored in the accuracy variable."
      ],
      "metadata": {
        "id": "shu-7PeHMS7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Outcome for New Pateint X_new with parameters\n",
        "#Pregnancies\tGlucose\tBloodPressure\tSkinThickness\tInsulin\tBMI\tDiabetesPedigreeFunction\tAge\t\n",
        "#8\t183\t64\t0\t0\t23.3\t0.672\t32\n",
        "\n",
        "X_new =[[8,\t183\t,64\t,0,\t0\t,23.3\t,0.672\t,32]]"
      ],
      "metadata": {
        "id": "9mgqOGqWU6Z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU8CbPmmVYPi",
        "outputId": "e63ed6af-e493-49a4-a86e-b0532037ac8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 183, 64, 0, 0, 23.3, 0.672, 32]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_new)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uymb0m9YVa5l",
        "outputId": "13d407e1-87da-4e87-c0c4-2679c48f41ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 160ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmwhmHboVhit",
        "outputId": "4eaec970-dfc4-4cbc-a6e3-16abef2124be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.93569064]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np  #This will convert the predicted probabilities to binary labels using a threshold of 0.5.\n",
        "# The resulting y_pred_binary array will contain 1's and 0's indicating the predicted class label for each input instance.\n",
        "\n",
        "threshold = 0.5\n",
        "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n"
      ],
      "metadata": {
        "id": "1Q894-w8WEZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjU4gn1bWHUv",
        "outputId": "58380cc7-67c3-4e33-92e7-b3efd508d32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}